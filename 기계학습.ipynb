{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## 의류 이미지 분류와 Grad-CAM을 이용한 영역 모델 해석\n",
        "\n",
        "> 이미지 데이터를 어떻게 처리하고 딥러닝을 해석할 것인지 고민할 필요가 있다.\n"
      ],
      "metadata": {
        "id": "bLRosGU1p6Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline  \n",
        "\n",
        "import matplotlib as mpl \n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.font_manager as fm  \n",
        "\n",
        "!apt-get update -qq\n",
        "!apt-get install fonts-nanum* -qq\n",
        "\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf' \n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "print(font_name)\n",
        "plt.rc('font', family=font_name)\n",
        "\n",
        "fm._rebuild()\n",
        "mpl.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "FqbyriLmeeuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkYxp3ILoPWO"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "from matplotlib import font_manager, rc\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchsummary import summary\n",
        "import torchvision\n",
        "\n",
        "from torchvision import transforms\n",
        "import albumentations as A\n",
        "from albumentations import Compose\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "from sklearn.metrics import f1_score, precision_score\n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings(action = 'ignore')\n",
        "\n",
        "print(A.__version__)\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "9JE5SkkWoV_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device "
      ],
      "metadata": {
        "id": "-hFWbBsWpmT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = False\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "QRY8ZqlcpoRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/data/musinsa_high/musinsa.csv\", index_col = 0)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "VU3k-3CYpqzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small = df.sample(frac=0.01)\n",
        "df_small.info()"
      ],
      "metadata": {
        "id": "DuB8LMJHIgGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 의류 이름 컬럼 생성\n",
        "def re_h(x):\n",
        "    x = re.compile('[a-zA-Z0-9/_.]').sub('', x).strip()\n",
        "    return x\n",
        "\n",
        "def cut_label(x):\n",
        "    x = x[:int(len(x)/2)]\n",
        "    return x"
      ],
      "metadata": {
        "id": "Kip3HlYWN2NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['name'] = df['path'].apply(re_h).apply(cut_label)\n",
        "df['name'].value_counts()"
      ],
      "metadata": {
        "id": "kkihiFs4Ip4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize = (15, 15)),\n",
        "# label_count = df['label'].value_counts()\n",
        "# label_count\n",
        "# label_count = df['name'].value_counts()\n",
        "\n",
        "# sns.barplot(x = df['name'], y = df['name'].value_counts())"
      ],
      "metadata": {
        "id": "snHZT9jwzffD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fig = plt.figure(figsize = (15, 15))\n",
        "\n",
        "# sns.barplot(x = df_small['name'], y = df_small['label'])"
      ],
      "metadata": {
        "id": "o0MVXmPuXfWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# custom_dataset 생성\n",
        "\n",
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self, x, y = None, transforms = None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.transforms = transforms\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = Image.open(self.x[idx]).convert(\"RGB\")\n",
        "        img = np.array(img)\n",
        "        label = self.y[idx]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(image = img)\n",
        "            img = img['image']\n",
        "            \n",
        "        return img, label"
      ],
      "metadata": {
        "id": "B6EeQuh7rX9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    # A.CenterCrop(224, 224, always_apply=True, p=1.0), \n",
        "    A.Normalize(mean = (0.48, 0.48, 0.48), std = (0.48, 0.48, 0.48)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    # A.CenterCrop(224, 224, always_apply=True, p=1.0),\n",
        "    A.Normalize(mean = (0.48, 0.48, 0.48), std = (0.48, 0.48, 0.48)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "transform = A.Compose([\n",
        "    A.Resize(256, 256),\n",
        "    # A.CenterCrop(224, 224, always_apply=True, p=1.0),\n",
        "    A.Normalize(mean = (0.48, 0.48, 0.48), std = (0.48, 0.48, 0.48)),\n",
        "    ToTensorV2()\n",
        "])"
      ],
      "metadata": {
        "id": "jHMmYbY3rcSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### train-val-test(8:1:1) 나누기"
      ],
      "metadata": {
        "id": "dxCzzHpT0PWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df['path'], df['label'],\n",
        "                                                  test_size = 0.3, shuffle = True,\n",
        "                                                  stratify = df['label'], random_state = 42)\n",
        "\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test,\n",
        "                                                  test_size = 0.5, shuffle = True,\n",
        "                                                  stratify = y_test, random_state = 42)\n",
        "\n",
        "x_train = list(x_train)\n",
        "x_val = list(x_val)\n",
        "y_train = list(y_train)\n",
        "y_val = list(y_val)\n",
        "x_test = list(x_test)\n",
        "y_test = list(y_test)"
      ],
      "metadata": {
        "id": "sKI-bjcGrd4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(df_small['path'], df_small['label'],\n",
        "#                                                   test_size = 0.3, shuffle = True,\n",
        "#                                                   stratify = df_small['label'], random_state = 42)\n",
        "\n",
        "# x_val, x_test, y_val, y_test = train_test_split(x_test, y_test,\n",
        "#                                                   test_size = 0.5, shuffle = True,\n",
        "#                                                   random_state = 42)\n",
        "\n",
        "# x_train = list(x_train)\n",
        "# x_val = list(x_val)\n",
        "# y_train = list(y_train)\n",
        "# y_val = list(y_val)\n",
        "# x_test = list(x_test)\n",
        "# y_test = list(y_test)"
      ],
      "metadata": {
        "id": "FwqjuS-lxBS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x_train: {len(x_train)}, y_train: {len(y_train)}\\nx_val: {len(x_val)}, y_val: {len(y_val)}\\nx_test: {len(x_test)}, y_test: {len(y_test)}')"
      ],
      "metadata": {
        "id": "4OVUK5o8uuF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoader\n",
        "# 배치 사이즈: 64\n",
        "# train만 shuffle 허용\n",
        "\n",
        "train_dataset = Custom_Dataset(x_train, y_train, transforms = transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True, drop_last = True, num_workers=6)\n",
        "\n",
        "val_dataset = Custom_Dataset(x_val, y_val, transforms = transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle = False, drop_last = True, num_workers=6)\n",
        "\n",
        "test_dataset = Custom_Dataset(x_test, y_test, transforms = test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 64, shuffle = False, drop_last = True, num_workers=0)"
      ],
      "metadata": {
        "id": "iP0tr1imrfY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 이미지와 transform 된 이미지 비교\n",
        "\n",
        "fig = plt.figure(figsize=(15, 15))\n",
        "def custom_imshow(img_transform, img):\n",
        "    img_transform = img_transform.numpy()\n",
        "    print(img_transform.shape)\n",
        "    print(img)\n",
        "    # img_transform = (img_transform * 255).astype(np.uint8)\n",
        "\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    ax1.set_title('Original_Image', size = 20)\n",
        "    ax1.axis(\"off\")\n",
        "\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "    plt.imshow(np.transpose(img_transform, (1, 2, 0))) # (channel\n",
        "    ax2.set_title('Transform_Image', size = 20)\n",
        "    ax2.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "img = Image.open(df.path[323]).convert('RGB')\n",
        "img = np.array(img)\n",
        "img_transform = transform(image = img)\n",
        "img_transform = img_transform['image']\n",
        "\n",
        "custom_imshow(img_transform, img)"
      ],
      "metadata": {
        "id": "YhbZXsIdrjbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience, verbose = False, delta = 0):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.counter = 0\n",
        "        self.delta = delta\n",
        "        self.path = '/content/drive/MyDrive/data/save_data/best_model.pth' # pth pt\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "    \n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).\\n Saving model ...\\n')\n",
        "            torch.save(model.state_dict(), self.path)\n",
        "            self.val_loss_min = val_loss\n",
        "            "
      ],
      "metadata": {
        "id": "hGv1crFrsNnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, epoch, scheduler, device):\n",
        "    model = model.to(device)\n",
        "    early_stopping = EarlyStopping(patience = 5, verbose = True) \n",
        "\n",
        "    train_losses, val_losses = [], [] # train, val loss 리스트로 저장\n",
        "\n",
        "    for epoch in range(epoch):\n",
        "        print(f\"\\n------ {epoch} epoch -------\\n\")\n",
        "        model.train()\n",
        "        train_loss_list = []\n",
        "        train_loss = 0.0\n",
        "        \n",
        "        for img, label in tqdm(iter(train_loader)):\n",
        "            img, label = img.to(device), label.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            pred = model(img)\n",
        "            loss = criterion(pred, label)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # train_loss += loss.item()\n",
        "\n",
        "            train_loss_list.append(loss.item())\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        val_loss = 0.0\n",
        "        val_loss_list = []\n",
        "        model_preds = []\n",
        "        true_labels = []\n",
        "\n",
        "        correct = 0\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for img, label in tqdm(iter(val_loader)):\n",
        "                img, label = img.to(device), label.to(device)\n",
        "                \n",
        "                val_pred = model(img)\n",
        "                v_loss = criterion(val_pred, label)\n",
        "\n",
        "                # val_loss += v_loss.item()\n",
        "\n",
        "                val_loss_list.append(v_loss.item()) \n",
        "\n",
        "                model_preds += val_pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "                true_labels += label.detach().cpu().numpy().tolist()\n",
        "\n",
        "                pred = val_pred.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "        \n",
        "        train_lossed = np.mean(train_loss_list)\n",
        "        val_lossed = np.mean(val_loss_list)\n",
        "\n",
        "        train_losses.append(train_lossed)\n",
        "        val_losses.append(val_lossed)\n",
        "\n",
        "        val_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "        precision = precision_score(true_labels, model_preds, average = 'micro')\n",
        "        f1 = f1_score(true_labels, model_preds, average = \"weighted\")\n",
        "\n",
        "\n",
        "        print(f\"\\nTrain loss: {train_lossed:.4f}\")\n",
        "        print(f\"Val Loss: {val_lossed:.4f}\")\n",
        "        print(f\"precsion ------> {precision:.5f}\")\n",
        "        print(f\"f1_score ------> {f1:.5f}\")\n",
        "        print(f\"{correct} / {len(val_loader.dataset)}, Accuracy: {val_accuracy:.3f}%\\n\")\n",
        "\n",
        "        early_stopping(val_lossed, model)\n",
        "        if early_stopping.early_stop:\n",
        "            print('Early Stopping')\n",
        "            break\n",
        "\n",
        "        model.load_state_dict(torch.load('/content/drive/MyDrive/data/save_data/best_model.pth'))\n",
        "    return train_losses, val_losses\n",
        "   "
      ],
      "metadata": {
        "id": "-YaDAGBl8Ec-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, test_loader, device):\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/data/save_data/best_model.pth'), strict = False)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()  # test eval \n",
        "    model_pred = []\n",
        "    true_labels = []\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for img, label in tqdm(iter(test_loader)):\n",
        "            img, label = img.to(device), label.to(device)\n",
        "            \n",
        "            test_pred = model(img)\n",
        "\n",
        "            model_pred += test_pred.argmax(1).detach().cpu().numpy().tolist()\n",
        "            true_labels += label.detach().cpu().numpy().tolist()\n",
        "\n",
        "            pred = test_pred.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "        \n",
        "    test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "    precision = precision_score(true_labels, model_pred, average = 'micro')\n",
        "    f1 = f1_score(true_labels, model_pred, average = \"weighted\")\n",
        "\n",
        "    print(f\"\\nprecsion ------> {precision:.5f}\")\n",
        "    print(f\"f1_score ------> {f1:.5f}\")\n",
        "    print(f\"{correct} / {len(test_loader.dataset)}, Accuracy: {test_accuracy:.3f}%\\n\")\n"
      ],
      "metadata": {
        "id": "KC8f39d22G-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet34(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet34, self).__init__()\n",
        "        self.model = torchvision.models.resnet50(pretrained = True)\n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, 29)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class MobilenetV2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MobilenetV2, self).__init__()\n",
        "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.model.classifier[1] = nn.Linear(1280, 29)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.drop(x)\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "class Efficientnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Efficientnet, self).__init__()\n",
        "        self.model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=True)\n",
        "        self.drop = nn.Dropout(p = 0.3)\n",
        "        self.model.classifier.fc = nn.Linear(1280, 29)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.drop(x)\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "Qbr1tJXZXqlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 메모리 캐시 정리\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "UQdtTwAAot9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 1 epoch 기준 \n",
        "resnet = ResNet34() # 7분 42초\n",
        "mobilenet = MobilenetV2() # 3분 13초\n",
        "efficientnet = Efficientnet() # 4분 5초"
      ],
      "metadata": {
        "id": "Xn7hv7EkMsSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_optimizer = optim.Adam(params = resnet.parameters(), lr = 0.001)\n",
        "resnet_scheduler = optim.lr_scheduler.LambdaLR(resnet_optimizer, lr_lambda = lambda epoch:0.95**epoch,\n",
        "                                        last_epoch = -1, verbose = False)\n",
        "    \n",
        "train_loss, val_loss = train(resnet, resnet_optimizer, 20, resnet_scheduler, device)"
      ],
      "metadata": {
        "id": "rIurb0Y5Zgo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_optimizer = optim.Adam(params = mobilenet.parameters(), lr = 0.001)\n",
        "scheduler = optim.lr_scheduler.LambdaLR(mobilenet_optimizer, lr_lambda = lambda epoch:0.95**epoch,\n",
        "                                         last_epoch = -1, verbose = False)\n",
        "\n",
        "train_loss, val_loss = train(mobilenet, mobilenet_optimizer, 20, scheduler, device)"
      ],
      "metadata": {
        "id": "v7agdEIruQv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_optimizer = optim.Adam(params = efficientnet.parameters(), lr = 0.001)\n",
        "efficientnet_scheduler = optim.lr_scheduler.LambdaLR(efficientnet_optimizer, lr_lambda = lambda epoch:0.95**epoch,\n",
        "                                                     last_epoch = -1, verbose = False)\n",
        "    \n",
        "train_loss, val_loss = train(efficientnet, efficientnet_optimizer, 20, efficientnet_scheduler, device)"
      ],
      "metadata": {
        "id": "plYYh7rDUtNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train , val loss 시각화\n",
        "\n",
        "fig = plt.figure(figsize = (12, 12))\n",
        "plt.plot(train_loss, marker = 'o', label='train_loss')\n",
        "plt.plot(val_loss, marker = 'o', label='val_loss')\n",
        "plt.legend()\n",
        "plt.title('train vs valid')"
      ],
      "metadata": {
        "id": "RYecDKdX1ch7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(mobilenet, test_loader, device)"
      ],
      "metadata": {
        "id": "xBRl4DwX2J2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 layer\n",
        "# \n",
        "final_conv = mobilenet.model.features[18]\n",
        "print(final_conv)\n",
        "fc_params = list(mobilenet.model.classifier.parameters())"
      ],
      "metadata": {
        "id": "HDseyKCJFDLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 현재 Grad-CAM 시각화 진행 중"
      ],
      "metadata": {
        "id": "dTWC0b5t2xwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    \"\"\" Extract pretrained activations\"\"\"\n",
        "    features = None\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = ((output.cpu()).data).numpy()\n",
        "    def remove(self):\n",
        "        self.hook.remove()\n",
        "\n",
        "\n",
        "# def getCAM(feature_conv, weight_fc, class_idx, cur_images):\n",
        "#     _, nc, h, w = feature_conv.shape\n",
        "\n",
        "#     cam = weight_fc[class_idx].dot(feature_conv[0, :, :, ].reshape((nc, h*w)))\n",
        "#     # print(cam)\n",
        "#     fig = plt.figure(figsize=(30, 30))\n",
        "#     # cam = cam[0, :].reshape(h, w)\n",
        "#     # cam = cam - np.min(cam)\n",
        "#     # cam_img = cam / np.max(cam)\n",
        "#     # print(cam_img.shape)\n",
        "#     for i in range(10):\n",
        "#         cam = weight_fc[class_idx].dot(feature_conv[0, :, :, ].reshape((nc, h*w)))\n",
        "#         cam = cam[i, :].reshape(h, w)\n",
        "#         cam = cam - np.min(cam)\n",
        "#         cam_img = cam / np.max(cam)\n",
        "#         # cam_img = cam_img.astype(np.uint16)\n",
        "        \n",
        "#         ax = fig.add_subplot(1, 10, i+1, xticks=[], yticks=[])\n",
        "#         plt.imshow(cv2.cvtColor(cur_images[i], cv2.COLOR_BGR2RGB))\n",
        "#         plt.imshow(cv2.resize(cam_img, (224, 224), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "#         ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n",
        "#         # return cam_img\n",
        "\n",
        "\n",
        "\n",
        "def plotGradCAM(model, final_conv, fc_params, train_loader, \n",
        "                row=1, col=10, img_size=224, device='cpu', original=False):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/data/save_data/best_model.pth'), strict = False)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    # save activated_features from conv\n",
        "    activated_features = SaveFeatures(final_conv)\n",
        "    # save weight from fc\n",
        "    weight = np.squeeze(fc_params[0].cpu().data.numpy())\n",
        "    # original images\n",
        "    # heatmap images\n",
        "\n",
        "    # fig = plt.figure(figsize=(10, 10))\n",
        "    for i, (img, target) in enumerate(test_loader):\n",
        "        output = model(img.to(device))\n",
        "        pred_idx = output.to('cpu').numpy().argmax(1)\n",
        "        cur_images = img.cpu().numpy().transpose((0, 2, 3, 1))\n",
        "\n",
        "        # getCAM(activated_features.features, weight, pred_idx, cur_images)\n",
        "\n",
        "        _, nc, h, w = activated_features.features.shape # chanel, height, width 언패킹\n",
        "\n",
        "        # cam = weight[pred_idx].dot(activated_features.features[0, :, :, ].reshape((nc, h*w)))\n",
        "        # print(cam)\n",
        "        fig = plt.figure(figsize=(30, 30))\n",
        "        # cam = cam[0, :].reshape(h, w)\n",
        "        # cam = cam - np.min(cam)\n",
        "        # cam_img = cam / np.max(cam)\n",
        "        # print(cam_img.shape)\n",
        "        for i in range(len(img)):\n",
        "            cam = weight[pred_idx].dot(activated_features.features[0, :, :, ].reshape((nc, h*w)))\n",
        "            cam = cam[i, :].reshape(h, w)\n",
        "            cam = cam - np.min(cam)\n",
        "            cam_img = cam / np.max(cam)\n",
        "            # cam_img = cam_img.astype(np.uint16)\n",
        "            ax = fig.add_subplot(1, 5, i+1, xticks=[], yticks=[])\n",
        "            plt.imshow(cv2.cvtColor(cur_images[i], cv2.COLOR_BGR2RGB))\n",
        "            plt.imshow(cv2.resize(cam_img, (224, 224), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "            # ax.set_title('Label:%s, Predict:%s'% (df['name'].unique()[target[i]], df['name'].unique()[pred_idx[i]]), fontsize=14)\n",
        "            ax.set_title('Label:%d, Predict:%d'% (target[i], pred_idx[i]), fontsize=14)\n",
        "        # heatmap = getCAM(activated_features.features, weight, pred_idx)\n",
        "        # ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n",
        "\n",
        "        # plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n",
        "        # plt.imshow(cv2.resize(heatmap, (img_size, img_size), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "        # ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n",
        "        if i == row*col-1:\n",
        "            break\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "wCUyS2eB0yFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SaveFeatures():\n",
        "    \"\"\" Extract pretrained activations\"\"\"\n",
        "    features = None\n",
        "    def __init__(self, m):\n",
        "        self.hook = m.register_forward_hook(self.hook_fn)\n",
        "    def hook_fn(self, module, input, output):\n",
        "        self.features = ((output.cpu()).data).numpy()\n",
        "    def remove(self):\n",
        "        self.hook.remove()\n",
        "\n",
        "\n",
        "\n",
        "def getCAM(feature_conv, weight_fc, class_idx, cur_images):\n",
        "    _, nc, h, w = feature_conv.shape\n",
        "\n",
        "    cam = weight_fc[class_idx].dot(feature_conv[0, :, :, ].reshape((nc, h*w)))\n",
        "    # print(cam)\n",
        "    fig = plt.figure(figsize=(30, 30))\n",
        "    # cam = cam[0, :].reshape(h, w)\n",
        "    # cam = cam - np.min(cam)\n",
        "    # cam_img = cam / np.max(cam)\n",
        "    # print(cam_img.shape)\n",
        "    for i in range(10):\n",
        "        cam = weight_fc[class_idx].dot(feature_conv[0, :, :, ].reshape((nc, h*w)))\n",
        "        cam = cam[i, :].reshape(h, w)\n",
        "        cam = cam - np.min(cam)\n",
        "        cam_img = cam / np.max(cam)\n",
        "        # cam_img = cam_img.astype(np.uint16)\n",
        "        \n",
        "        ax = fig.add_subplot(1, 10, i+1, xticks=[], yticks=[])\n",
        "        plt.imshow(cv2.cvtColor(cur_images[i], cv2.COLOR_BGR2RGB))\n",
        "        plt.imshow(cv2.resize(cam_img, (224, 224), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "        ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n",
        "        # return cam_img\n",
        "\n",
        "\n",
        "\n",
        "def plotGradCAM(model, final_conv, fc_params, train_loader, \n",
        "                row=1, col=10, img_size=224, device='cpu', original=False):\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/data/save_data/best_model.pth'), strict = False)\n",
        "    model.to(device)\n",
        "\n",
        "    model_pred = []\n",
        "    true_labels = []\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    # save activated_features from conv\n",
        "    activated_features = SaveFeatures(final_conv)\n",
        "    # save weight from fc\n",
        "    weight = np.squeeze(fc_params[0].cpu().data.numpy())\n",
        "    # original images\n",
        "    # heatmap images\n",
        "\n",
        "    # fig = plt.figure(figsize=(10, 10))\n",
        "    for img, target in tqdm(iter(test_loader)):\n",
        "        output = model(img.to(device))\n",
        "        pred_idx = output.to('cpu').numpy().argmax(1)\n",
        "        cur_images = img.cpu().numpy().transpose((0, 2, 3, 1))\n",
        "\n",
        "        # getCAM(activated_features.features, weight, pred_idx, cur_images)\n",
        "\n",
        "        _, nc, h, w = activated_features.features.shape # chanel, height, width 언패킹\n",
        "        fig = plt.figure(figsize=(30, 30))\n",
        "\n",
        "        for i in range(5):\n",
        "            cam = weight[pred_idx].dot(activated_features.features[0, :, :, ].reshape((nc, h*w)))\n",
        "            cam = cam[i, :].reshape(h, w)\n",
        "            cam = cam - np.min(cam)\n",
        "            cam_img = cam / np.max(cam)\n",
        "\n",
        "            ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n",
        "            plt.imshow(cv2.cvtColor(cur_images[i], cv2.COLOR_BGR2RGB))\n",
        "            plt.imshow(cv2.resize(cam_img, (224, 224), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "            # ax.set_title('Label:%s, Predict:%s'% (df['name'].unique()[target[i]], df['name'].unique()[pred_idx[i]]), fontsize=14)\n",
        "            ax.set_title('Label:%d, Predict:%d'% (target[i], pred_idx[i]), fontsize=14)\n",
        "        # heatmap = getCAM(activated_features.features, weight, pred_idx)\n",
        "        # ax = fig.add_subplot(row, col, i+1, xticks=[], yticks=[])\n",
        "\n",
        "        # plt.imshow(cv2.cvtColor(cur_images[0], cv2.COLOR_BGR2RGB))\n",
        "        # plt.imshow(cv2.resize(heatmap, (img_size, img_size), interpolation=cv2.INTER_LINEAR), alpha=0.4, cmap='jet')\n",
        "        # ax.set_title('Label:%d, Predict:%d' % (target, pred_idx), fontsize=14)\n",
        "            if i == row*col-1:\n",
        "                break\n",
        "\n",
        "        model_pred += output.argmax(1).detach().cpu().numpy().tolist()\n",
        "        true_labels += target.detach().cpu().numpy().tolist()\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "        \n",
        "\n",
        "    test_accuracy = 100 * correct / len(test_loader.dataset)\n",
        "    precision = precision_score(true_labels, model_pred, average = 'micro')\n",
        "    f1 = f1_score(true_labels, model_pred, average = \"weighted\")\n",
        "\n",
        "    print(f\"\\nprecsion ------> {precision:.5f}\")\n",
        "    print(f\"f1_score ------> {f1:.5f}\")\n",
        "    print(f\"{correct} / {len(test_loader.dataset)}, Accuracy: {test_accuracy:.3f}%\\n\")\n",
        "\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "V-hNIBCp1gCY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore')"
      ],
      "metadata": {
        "id": "1FmmhfD43--X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class SaveFeatures():\n",
        "#     features = None\n",
        "#     def __init__(self, m):\n",
        "#         self.hook = m.register_forward_hook(self.hook_fn)\n",
        "\n",
        "#     def hook_fn(self, module, input, output):\n",
        "#         self.features = ((output.cpu()).data).numpy()\n",
        "\n",
        "#     def remove(self):\n",
        "#         self.hook.remove()\n",
        "\n",
        "# def getCAM(feature_conv, weight_fc, class_idx):\n",
        "#     _, nc, h, w = feature_conv.shape\n",
        "\n",
        "#     cam = weight_fc[class_idx].dot(feature_conv[0, :, :, ].reshape((nc, h*w)))\n",
        "    \n",
        "#     cam = cam[0, :].reshape(h, w)\n",
        "\n",
        "#     print(cam)\n",
        "#     cam = cam - np.min(cam)\n",
        "#     cam_img = cam / np.max(cam)\n",
        "#     return cam_img\n",
        "\n",
        "# def plotGradCAM(model, final_conv, fc_params, test_loader, row = 1, col = 8,\n",
        "#                 img_size = 224, device = device, original = False):\n",
        "#     model.to(device)\n",
        "#     model.eval()\n",
        "\n",
        "#     model_pred = []\n",
        "#     true_labels = []\n",
        "\n",
        "#     activated_features = SaveFeatures(final_conv)\n",
        "#     weight = np.squeeze(fc_params[0].cpu().data.numpy())\n",
        "\n",
        "\n",
        "#     for i, (img, label) in enumerate(test_loader):\n",
        "#         img, label = img.to(device), label.to(device)\n",
        "\n",
        "#         test_pred = model(img)\n",
        "#         pred_idx = test_pred.detach().cpu().numpy().argmax(1)\n",
        "#         cur_images = img.detach().cpu().numpy()\n",
        "#         cur_images = img.detach().cpu().numpy().transpose((0, 2, 3, 1))\n",
        "#         heatmap = getCAM(activated_features.features, weight, pred_idx)\n",
        "#         print(heatmap)\n",
        "            "
      ],
      "metadata": {
        "id": "C6iKLPHRhL8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotGradCAM(mobilenet, final_conv, fc_params, test_loader)"
      ],
      "metadata": {
        "id": "hc7zSBpexcC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mNw2BZnDAZvK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}